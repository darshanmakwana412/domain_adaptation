{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn, optim\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyDKQxsRaRhv",
        "outputId": "7e3654df-95de-40c9-f2c5-e7ebde5b22d0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(pretrained=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qydz6Z2sakYS",
        "outputId": "582a859b-a89b-4104-f216-c0a6658254e8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5mKC1SFa06W",
        "outputId": "d5e52fa2-3728-4aad-b630-103f4bc27a67"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "rDfaA1hqa6gU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in trainloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(trainloader):.4f}')\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUW9Rhzpa-3P",
        "outputId": "92c13fe3-137c-409a-de6c-0dac5a5d57d6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/15], Loss: 0.8312\n",
            "Epoch [2/15], Loss: 0.9120\n",
            "Epoch [3/15], Loss: 0.7170\n",
            "Epoch [4/15], Loss: 0.5610\n",
            "Epoch [5/15], Loss: 0.4684\n",
            "Epoch [6/15], Loss: 0.3825\n",
            "Epoch [7/15], Loss: 0.3180\n",
            "Epoch [8/15], Loss: 0.2575\n",
            "Epoch [9/15], Loss: 0.3781\n",
            "Epoch [10/15], Loss: 0.2326\n",
            "Epoch [11/15], Loss: 0.1493\n",
            "Epoch [12/15], Loss: 0.1299\n",
            "Epoch [13/15], Loss: 0.1253\n",
            "Epoch [14/15], Loss: 0.1111\n",
            "Epoch [15/15], Loss: 0.0968\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ],
      "metadata": {
        "id": "VsL2KxwObE1e"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(testloader)\n",
        "images, labels = next(data_iter)\n",
        "images, labels = images[0].unsqueeze(0).to(device), labels[0].item()"
      ],
      "metadata": {
        "id": "g8qOyrzQexPH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_layers = [model.layer4[-1]]\n",
        "targets = [ClassifierOutputTarget(labels)]"
      ],
      "metadata": {
        "id": "dccSjZ5AfB_d"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(testloader)\n",
        "images, labels = next(data_iter)\n",
        "image, label = images[0].unsqueeze(0).to(device), labels[0].item()\n",
        "\n",
        "target_layers = [model.layer4[-1]]\n",
        "targets = [ClassifierOutputTarget(label)]\n",
        "\n",
        "with GradCAM(model=model, target_layers=target_layers) as cam:\n",
        "    grayscale_cam = cam(input_tensor=image, targets=targets)\n",
        "    grayscale_cam = grayscale_cam[0, :]\n",
        "    rgb_img = image.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        "    rgb_img = (rgb_img * 0.5 + 0.5)\n",
        "    rgb_img = np.clip(rgb_img, 0, 1)\n",
        "    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "Image.fromarray((visualization * 255).astype(np.uint8)).show()"
      ],
      "metadata": {
        "id": "VlnxOyibf9ma"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(testloader)\n",
        "images, labels = next(data_iter)\n",
        "image, label = images[0].unsqueeze(0).to(device), labels[0].item()\n",
        "\n",
        "# Initialize Grad-CAM\n",
        "target_layers = [model.layer4[-1]]  # Use the last layer of ResNet\n",
        "targets = [ClassifierOutputTarget(label)]\n",
        "\n",
        "with GradCAM(model=model, target_layers=target_layers) as cam:\n",
        "    grayscale_cam = cam(input_tensor=image, targets=targets)\n",
        "    grayscale_cam = grayscale_cam[0, :]  # Get the CAM for the first image in the batch\n",
        "\n",
        "    # Convert the input image to a numpy array for visualization\n",
        "    rgb_img = image.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
        "    rgb_img = (rgb_img * 0.5 + 0.5)  # Denormalize to [0, 1]\n",
        "    rgb_img = np.clip(rgb_img, 0, 1)  # Ensure values are between 0 and 1\n",
        "\n",
        "    # Visualize the CAM on the image\n",
        "    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "# Display the visualization using matplotlib\n",
        "plt.imshow(visualization)\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "b7FjqUr4gTio",
        "outputId": "17a43846-082b-43b1-83b1-2d8356b70a36"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LhPLeEQ1gcuz"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}