{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ba5194-87c9-4243-978a-5b0cb748f7fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0c954-8ab3-4b0e-b490-7ac7a59f6f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "class DataManager:\n",
    "    def __init__(self, root_dir: str = \"./data\", size: tuple[int, int] = (256, 256)) -> None:\n",
    "        \n",
    "        self.domains = [dirs for dirs in os.listdir(root_dir) if dirs not in [\"train\", \"test\"]]\n",
    "        print(f\"{len(self.domains)} domains found: {self.domains}\")\n",
    "\n",
    "        self.size = size\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "        self.transforms = transforms.ToTensor()\n",
    "\n",
    "        num_class = {}\n",
    "        self.data = {\n",
    "            \"train\": {},\n",
    "            \"test\": {}\n",
    "        }\n",
    "        for domain in self.domains:\n",
    "            domain_dir = os.path.join(root_dir, domain)\n",
    "            for class_dir in os.listdir(domain_dir):\n",
    "                if class_dir not in num_class:\n",
    "                    num_class[class_dir] = 0\n",
    "                num_class[class_dir] += 1\n",
    "\n",
    "            for split in [\"train\", \"test\"]:\n",
    "                with open(os.path.join(root_dir, split, f\"{domain}_{split}.txt\")) as f:\n",
    "                    self.data[split][domain] = [[line.strip().split()[0], int(line.strip().split()[1])] for line in f.readlines()]\n",
    "\n",
    "        underact = 0\n",
    "        for key, val in num_class.items():\n",
    "            if val != len(self.domains):\n",
    "                print(f\"class {key} only found in {val} domains\")\n",
    "                underact += 1\n",
    "\n",
    "        if underact:\n",
    "            print(f\"{underact} classes are in minority across the domains\")\n",
    "        else:\n",
    "            print(f\"All classes are present across all the domains\")\n",
    "\n",
    "        print(f\"Total number of classes: {len(num_class)}\")\n",
    "\n",
    "    def sample(self, domain: str, split: str = \"train\", batch_size: int = 1, return_tensors: bool = False) -> Union[\n",
    "        Optional[tuple[Image.Image, int]],\n",
    "        Optional[tuple[list[Image.Image], list[int]]],\n",
    "        Optional[tuple[torch.Tensor, torch.Tensor]]\n",
    "    ]:\n",
    "\n",
    "        \"\"\"\n",
    "        Samples data points from the specified domain and split\n",
    "    \n",
    "        Args:\n",
    "            domain (str): The domain to sample from. Must be one of the available domains in the dataset.\n",
    "            split (str, optional): The dataset split to use. Defaults to \"train\".\n",
    "            batch_size (int, optional): Number of samples to return. Defaults to 1.\n",
    "            return_tensors (bool, optional): If True, returns PyTorch tensors instead of PIL images. Defaults to False.\n",
    "    \n",
    "        Returns:\n",
    "            Union[\n",
    "                Optional[tuple[Image.Image, int]],\n",
    "                Optional[tuple[list[Image.Image], list[int]]],\n",
    "                Optional[tuple[torch.Tensor, torch.Tensor]]\n",
    "            ]\n",
    "        \"\"\"\n",
    "        \n",
    "        if domain not in self.domains:\n",
    "            print(f\"Domain: {domain} not found in the dataset, available domains are: {self.domains}\")\n",
    "            return None\n",
    "\n",
    "        samples = random.choices(self.data[split][domain], k=batch_size)\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for img_path, idx in samples:\n",
    "            img = Image.open(os.path.join(self.root_dir, img_path)).convert(\"RGB\").resize(self.size)\n",
    "            images.append(img)\n",
    "            labels.append(idx)\n",
    "\n",
    "        if return_tensors:\n",
    "            images = torch.stack([self.transforms(img) for img in images])\n",
    "            labels = torch.tensor(labels)\n",
    "            return (images, labels)\n",
    "        else:\n",
    "            if batch_size == 1:\n",
    "                return (images[0], labels[0])\n",
    "            else:\n",
    "                return (images, labels)\n",
    "\n",
    "data_manager = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb9105-14d7-4a55-a747-b46d82f2100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[img, idx] = data_manager.sample(\"real\", batch_size = 10, return_tensors = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bbee29-4b6d-41e5-9a27-bfe83e0d410d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369b81b-7003-4b90-ac00-be95072af87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels, self.out_channels =  in_channels, out_channels\n",
    "        self.blocks = nn.Identity()\n",
    "        self.shortcut = nn.Identity()   \n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
    "        x = self.blocks(x)\n",
    "        x += residual\n",
    "        return x\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.out_channels\n",
    "\n",
    "class ResNetResidualBlock(ResidualBlock):\n",
    "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
    "        self.shortcut = nn.Sequential(OrderedDict(\n",
    "        {\n",
    "            'conv' : nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
    "                      stride=self.downsampling, bias=False),\n",
    "            'bn' : nn.BatchNorm2d(self.expanded_channels)\n",
    "            \n",
    "        })) if self.should_apply_shortcut else None\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def expanded_channels(self):\n",
    "        return self.out_channels * self.expansion\n",
    "    \n",
    "    @property\n",
    "    def should_apply_shortcut(self):\n",
    "        return self.in_channels != self.expanded_channels\n",
    "        \n",
    "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
    "    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, *args, **kwargs), \n",
    "                          'bn': nn.BatchNorm2d(out_channels) }))\n",
    "\n",
    "class ResNetBasicBlock(ResNetResidualBlock):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
    "            activation(),\n",
    "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
    "        )\n",
    "    \n",
    "\n",
    "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
    "        self.blocks = nn.Sequential(\n",
    "           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n",
    "             activation(),\n",
    "             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n",
    "             activation(),\n",
    "             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n",
    "        )\n",
    "    \n",
    "\n",
    "class ResNetLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        downsampling = 2 if in_channels != out_channels else 1\n",
    "        \n",
    "        self.blocks = nn.Sequential(\n",
    "            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n",
    "            *[block(out_channels * block.expansion, \n",
    "                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return x\n",
    "\n",
    "class ResNetEncoder(nn.Module):\n",
    "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2], \n",
    "                 activation=nn.ReLU, block=ResNetBasicBlock, *args,**kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.blocks_sizes = blocks_sizes\n",
    "        \n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(self.blocks_sizes[0]),\n",
    "            activation(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
    "        self.blocks = nn.ModuleList([ \n",
    "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n",
    "                        block=block,  *args, **kwargs),\n",
    "            *[ResNetLayer(in_channels * block.expansion, \n",
    "                          out_channels, n=n, activation=activation, \n",
    "                          block=block, *args, **kwargs) \n",
    "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.gate(x)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        return x\n",
    "\n",
    "class ResnetDecoder(nn.Module):\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super().__init__()\n",
    "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.decoder = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.avg(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.in_channels = in_channels\n",
    "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
    "        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(model_name: str, n_classes: Optional[int] = None, in_channels: int = 3) -> 'ResNet':\n",
    "\n",
    "        model_configs = {\n",
    "            \"resnet18\": {\"block\": ResNetBasicBlock, \"depths\": [2, 2, 2, 2]},\n",
    "            \"resnet34\": {\"block\": ResNetBasicBlock, \"depths\": [3, 4, 6, 3]},\n",
    "            \"resnet50\": {\"block\": ResNetBottleNeckBlock, \"depths\": [3, 4, 6, 3]},\n",
    "            \"resnet101\": {\"block\": ResNetBottleNeckBlock, \"depths\": [3, 4, 23, 3]},\n",
    "            \"resnet152\": {\"block\": ResNetBottleNeckBlock, \"depths\": [3, 8, 36, 3]}\n",
    "        }\n",
    "\n",
    "        if model_name[-4:] == \".pth\":\n",
    "            ckpt = torch.load(model_name, weights_only = False)\n",
    "            model_name = ckpt[\"model_type\"]\n",
    "            n_classes = ckpt[\"n_classes\"]\n",
    "            in_channels = ckpt[\"in_channels\"]\n",
    "        \n",
    "        config = model_configs.get(model_name.lower())\n",
    "        \n",
    "        if config:\n",
    "            model = ResNet(in_channels, n_classes, block=config[\"block\"], depths=config[\"depths\"])\n",
    "            model.model_name = model_name\n",
    "        else:\n",
    "            raise ValueError(f\"{model_name} not implemented, available models are: {list(model_configs.keys())}\")\n",
    "\n",
    "        if model_name[-4:] == \".pth\":\n",
    "            model.load_state_dict(ckpt[\"state_dict\"])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def save_model(self, path: str) -> None:\n",
    "        ckpt = {\n",
    "            \"model_type\": self.model_name,\n",
    "            \"n_classes\": self.n_classes,\n",
    "            \"in_channels\": self.in_channels,\n",
    "            \"state_dict\": self.state_dict() \n",
    "        }\n",
    "        torch.save(ckpt, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df831082-f116-43ff-95dc-9d88b4b05091",
   "metadata": {},
   "source": [
    "## Base Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60c7f38-5025-43b1-9843-d1964ab03724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DataManager\n",
    "from models import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09188c73-0553-4abd-ad5a-3e60721aad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 domains found: ['real', 'quickdraw', 'clipart', 'painting', 'sketch']\n",
      "All classes are present across all the domains\n",
      "Total number of classes: 345\n"
     ]
    }
   ],
   "source": [
    "data_manager = DataManager(root_dir = \"./data\")\n",
    "\n",
    "model = ResNet.load_model(\"resnet50\", n_classes = 345, in_channels = 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
