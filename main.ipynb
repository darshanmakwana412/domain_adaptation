{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53ba5194-87c9-4243-978a-5b0cb748f7fa",
   "metadata": {},
   "source": [
    "## Dataset Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f3a0c954-8ab3-4b0e-b490-7ac7a59f6f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 domains found: ['real', 'quickdraw', 'clipart', 'painting', 'sketch']\n",
      "All classes are present across all the domains\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "class DataManager:\n",
    "    def __init__(self, root_dir: str = \"./data\", size: tuple[int, int] = (256, 256)) -> None:\n",
    "        \n",
    "        self.domains = [dirs for dirs in os.listdir(root_dir) if dirs not in [\"train\", \"test\"]]\n",
    "        print(f\"{len(self.domains)} domains found: {self.domains}\")\n",
    "\n",
    "        self.size = size\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "        self.transforms = transforms.ToTensor()\n",
    "\n",
    "        num_class = {}\n",
    "        self.data = {\n",
    "            \"train\": {},\n",
    "            \"test\": {}\n",
    "        }\n",
    "        for domain in self.domains:\n",
    "            domain_dir = os.path.join(root_dir, domain)\n",
    "            for class_dir in os.listdir(domain_dir):\n",
    "                if class_dir not in num_class:\n",
    "                    num_class[class_dir] = 0\n",
    "                num_class[class_dir] += 1\n",
    "\n",
    "            for split in [\"train\", \"test\"]:\n",
    "                with open(os.path.join(root_dir, split, f\"{domain}_{split}.txt\")) as f:\n",
    "                    self.data[split][domain] = [[line.strip().split()[0], int(line.strip().split()[1])] for line in f.readlines()]\n",
    "\n",
    "        underact = 0\n",
    "        for key, val in num_class.items():\n",
    "            if val != len(self.domains):\n",
    "                print(f\"class {key} only found in {val} domains\")\n",
    "                underact += 1\n",
    "\n",
    "        if underact:\n",
    "            print(f\"{underact} classes are in minority across the domains\")\n",
    "        else:\n",
    "            print(f\"All classes are present across all the domains\")\n",
    "\n",
    "    def sample(self, domain: str, split: str = \"train\", batch_size: int = 1, return_tensors: bool = False) -> Union[\n",
    "        Optional[tuple[Image.Image, int]],\n",
    "        Optional[tuple[list[Image.Image], list[int]]],\n",
    "        Optional[tuple[torch.Tensor, torch.Tensor]]\n",
    "    ]:\n",
    "\n",
    "        \"\"\"\n",
    "        Samples data points from the specified domain and split\n",
    "    \n",
    "        Args:\n",
    "            domain (str): The domain to sample from. Must be one of the available domains in the dataset.\n",
    "            split (str, optional): The dataset split to use. Defaults to \"train\".\n",
    "            batch_size (int, optional): Number of samples to return. Defaults to 1.\n",
    "            return_tensors (bool, optional): If True, returns PyTorch tensors instead of PIL images. Defaults to False.\n",
    "    \n",
    "        Returns:\n",
    "            Union[\n",
    "                Optional[tuple[Image.Image, int]],\n",
    "                Optional[tuple[list[Image.Image], list[int]]],\n",
    "                Optional[tuple[torch.Tensor, torch.Tensor]]\n",
    "            ]\n",
    "        \"\"\"\n",
    "        \n",
    "        if domain not in self.domains:\n",
    "            print(f\"Domain: {domain} not found in the dataset, available domains are: {self.domains}\")\n",
    "            return None\n",
    "\n",
    "        samples = random.choices(self.data[split][domain], k=batch_size)\n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for img_path, idx in samples:\n",
    "            img = Image.open(os.path.join(self.root_dir, img_path)).convert(\"RGB\").resize(self.size)\n",
    "            images.append(img)\n",
    "            labels.append(idx)\n",
    "\n",
    "        if return_tensors:\n",
    "            images = torch.stack([self.transforms(img) for img in images])\n",
    "            labels = torch.tensor(labels)\n",
    "            return (images, labels)\n",
    "        else:\n",
    "            if batch_size == 1:\n",
    "                return (images[0], labels[0])\n",
    "            else:\n",
    "                return (images, labels)\n",
    "\n",
    "data_manager = DataManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "10fb9105-14d7-4a55-a747-b46d82f2100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[img, idx] = data_manager.sample(\"real\", batch_size = 10, return_tensors = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
