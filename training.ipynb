{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0473cf-fbf7-481e-afb0-03ea0a69c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from aug.automold import add_rain, add_snow, add_fog, add_autumn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as tt\n",
    "from models import ResNet\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingLR\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1285bbb-e8b0-4bfb-92ac-ff60944b2f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_images = \"./stl10_binary/train_X.bin\"\n",
    "path_to_labels = \"./stl10_binary/train_y.bin\"\n",
    "\n",
    "with open(path_to_images, 'rb') as f:\n",
    "    images = np.fromfile(f, dtype=np.uint8)\n",
    "    images = np.reshape(images, (-1, 3, 96, 96))\n",
    "    train_images = np.transpose(images, (0, 3, 2, 1))\n",
    "\n",
    "with open(path_to_labels, 'rb') as f:\n",
    "    train_labels = np.fromfile(f, dtype=np.uint8) - 1\n",
    "\n",
    "path_to_images = \"./stl10_binary/test_X.bin\"\n",
    "path_to_labels = \"./stl10_binary/test_y.bin\"\n",
    "\n",
    "with open(path_to_images, 'rb') as f:\n",
    "    images = np.fromfile(f, dtype=np.uint8)\n",
    "    images = np.reshape(images, (-1, 3, 96, 96))\n",
    "    test_images = np.transpose(images, (0, 3, 2, 1))\n",
    "\n",
    "with open(path_to_labels, 'rb') as f:\n",
    "    labels = np.fromfile(f, dtype=np.uint8)\n",
    "    test_labels = labels - 1\n",
    "\n",
    "def shift(image, domain):\n",
    "    if domain == \"rain\":\n",
    "        return add_rain(image, rain_type = 'torrential')\n",
    "    elif domain == \"fog\":\n",
    "        return add_fog(image, fog_coeff=1.0)\n",
    "    elif domain == \"snow\":\n",
    "        return add_snow(image, snow_coeff=0.05)\n",
    "    elif domain == \"autumn\":\n",
    "        return add_autumn(image)\n",
    "    return image\n",
    "\n",
    "class STL10Dataset(Dataset):\n",
    "    def __init__(self, images, labels, domain=\"base\", transform=None):\n",
    "        self.images = images.astype(np.float32)\n",
    "        self.labels = labels.astype(np.int64)\n",
    "        self.transform = transform\n",
    "        self.domain = domain\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = shift(image, self.domain)\n",
    "        image[np.isnan(image)] = 0\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "stats = ((113.911194, 112.1515, 103.69485), (51.854874, 51.261967, 51.842403))\n",
    "train_tfms = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(stats[0], stats[1])\n",
    "])\n",
    "\n",
    "valid_tfms = tt.Compose([\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(stats[0], stats[1])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291521db-a0ab-4692-8764-b348f75f08fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "device = \"cuda:0\"\n",
    "lr = 5e-4\n",
    "batch_size = 256\n",
    "dtype = torch.bfloat16\n",
    "domain = \"autumn\"\n",
    "\n",
    "model = ResNet.load_model(model_name=\"resnet152\", n_classes=10)\n",
    "ckpt = torch.load(\"./models/resnet152_base.pth\")\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.train()\n",
    "model.to(device).to(dtype)\n",
    "\n",
    "train_dataset = STL10Dataset(test_images, test_labels, domain=domain, transform=train_tfms)\n",
    "test_dataset = STL10Dataset(train_images, train_labels, domain=domain, transform=valid_tfms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader) * num_epochs, eta_min=1e-5)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    pbar = tqdm(train_loader)\n",
    "    for images, labels in pbar:\n",
    "        \n",
    "        inputs, labels = images.to(device).to(dtype), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        pbar.set_description(f\"Loss: {loss.item()}, lr: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "        scheduler.step()\n",
    "    \n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader):\n",
    "            inputs, labels = images.to(device).to(dtype), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    val_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    print(\"Accuracy: \", accuracy * 100, \"Val Loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df24814f-b917-4a31-8796-d2ab60cbd8ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8f5f2c326447eebb7efb0fac536897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  63.32 Val Loss:  0.0062859375\n"
     ]
    }
   ],
   "source": [
    "from models import ResNet\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "device = \"cuda:7\"\n",
    "lr = 5e-4\n",
    "batch_size = 256\n",
    "dtype = torch.bfloat16\n",
    "domain = \"base\"\n",
    "\n",
    "model = ResNet.load_model(\"./models/resnet152_base.pth\")\n",
    "# model = ResNet.load_model(model_name=\"resnet152\", n_classes=10)\n",
    "# ckpt = torch.load(\"./models/resnet152_fog.pth\")\n",
    "# model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()\n",
    "model.to(device).to(dtype)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "test_dataset = STL10Dataset(train_images, train_labels, domain=domain, transform=valid_tfms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "total = 0\n",
    "total_loss = 0\n",
    "correct = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        inputs, labels = images.to(device).to(dtype), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "val_loss = total_loss / total\n",
    "accuracy = correct / total\n",
    "print(\"Accuracy: \", accuracy * 100, \"Val Loss: \", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b79937-48e9-41aa-86f8-c1596c5ad9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benchmarks (Accuracy %)\n",
    "# resnet152  base   rain    fog    autumn\n",
    "# base      63.32  29.04   54.14  26.77\n",
    "# rainy     26.02  60.26   32.36  26.38\n",
    "# foggy     51.55  39.9    62.92  24.14\n",
    "# autumn    16.25  11.98   17.26  39.16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
