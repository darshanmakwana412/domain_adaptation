{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ffcce2-65e9-42a9-b1ee-4d2070630ea0",
   "metadata": {},
   "source": [
    "## Editing Models with Task Arithematic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462db79f-352c-4005-96ea-416cfa981d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "np.complex = np.complex128\n",
    "import torch\n",
    "from aug.automold import add_rain, add_snow, add_fog, add_autumn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as tt\n",
    "from models import ResNet\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, CosineAnnealingLR, StepLR\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "# import imgaug.augmenters as iaa\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9277cb6-bca7-4456-a55f-dc8dcd68e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stl10(root_dir: str = \"stl10_binary\"):\n",
    "\n",
    "    path_to_images = os.path.join(root_dir, \"train_X.bin\")\n",
    "    path_to_labels = os.path.join(root_dir, \"train_y.bin\")\n",
    "    \n",
    "    with open(path_to_images, 'rb') as f:\n",
    "        images = np.fromfile(f, dtype=np.uint8)\n",
    "        images = np.reshape(images, (-1, 3, 96, 96))\n",
    "        train_images = np.transpose(images, (0, 3, 2, 1))\n",
    "    \n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        train_labels = np.fromfile(f, dtype=np.uint8) - 1\n",
    "    \n",
    "    path_to_images = os.path.join(root_dir, \"test_X.bin\")\n",
    "    path_to_labels = os.path.join(root_dir, \"test_y.bin\")\n",
    "    \n",
    "    with open(path_to_images, 'rb') as f:\n",
    "        images = np.fromfile(f, dtype=np.uint8)\n",
    "        images = np.reshape(images, (-1, 3, 96, 96))\n",
    "        test_images = np.transpose(images, (0, 3, 2, 1))\n",
    "    \n",
    "    with open(path_to_labels, 'rb') as f:\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "        test_labels = labels - 1\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "def add_snow(image, snowflake_count=200, snowflake_radius=(1, 3), snowflake_intensity=(200, 255)):\n",
    "    snowy_image = image.copy()\n",
    "    height, width, _ = snowy_image.shape\n",
    "    for _ in range(snowflake_count):\n",
    "        x = np.random.randint(0, width)\n",
    "        y = np.random.randint(0, height)\n",
    "        \n",
    "        radius = np.random.randint(snowflake_radius[0], snowflake_radius[1])\n",
    "        intensity = np.random.randint(snowflake_intensity[0], snowflake_intensity[1])\n",
    "        \n",
    "        cv2.circle(snowy_image, (x, y), radius, (intensity, intensity, intensity), -1)\n",
    "\n",
    "    return snowy_image\n",
    "\n",
    "def shift(image, domain):\n",
    "    if domain == \"rain\":\n",
    "        return add_rain(image, rain_type = 'torrential')\n",
    "    elif domain == \"fog\":\n",
    "        return add_fog(image, fog_coeff=1.0)\n",
    "    elif domain == \"snow\":\n",
    "        return add_snow(image=image)\n",
    "    elif domain == \"autumn\":\n",
    "        return add_autumn(image)\n",
    "    return image\n",
    "\n",
    "class STL10Dataset(Dataset):\n",
    "    def __init__(self, images, labels, domain=\"base\"):\n",
    "        self.images = images.astype(np.float32)\n",
    "        self.labels = labels.astype(np.int64)\n",
    "        self.domain = domain\n",
    "        self.domains = [\"rain\", \"fog\", \"snow\"]\n",
    "        stats = ((113.911194, 112.1515, 103.69485), (51.854874, 51.261967, 51.842403))\n",
    "        self.tfms = tt.Compose([\n",
    "            tt.ToTensor(),\n",
    "            tt.Normalize(stats[0], stats[1])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.domain == \"all\":\n",
    "            return len(self.domains) * len(self.images)\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.domain == \"all\":\n",
    "            d = idx // len(self.images)\n",
    "            idx = idx % len(self.images)\n",
    "            domain = self.domains[d]\n",
    "        else:\n",
    "            domain = self.domain\n",
    "        \n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = shift(image, domain)\n",
    "        \n",
    "        image[np.isnan(image)] = 0\n",
    "\n",
    "        image = self.tfms(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def evaluate(model, batch_size, num_workers, domains, device, dtype):\n",
    "    \n",
    "    train_images, train_labels, test_images, test_labels = load_stl10()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device).to(dtype)\n",
    "    result = {}\n",
    "\n",
    "    for domain in domains:\n",
    "        \n",
    "        test_dataset = STL10Dataset(test_images, test_labels, domain=domain)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                inputs, labels = images.to(device).to(dtype), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        result[domain] = {\n",
    "            \"loss\": total_loss / total,\n",
    "            \"accuracy\": correct / total\n",
    "        }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e387753e-3ab5-4773-a612-3784809686a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(domain):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    model.load_state_dict(torch.load(f\"./ckpts/resnet50_{domain}.pth\"))\n",
    "    return model\n",
    "\n",
    "base = load_model(\"base\")\n",
    "rain = load_model(\"rain\")\n",
    "fog = load_model(\"fog\")\n",
    "snow = load_model(\"snow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf5d4f94-60e2-4095-b404-eb4d4a20fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(model1, model2, device=\"cuda:7\", dtype=torch.float32):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    model.to(device).to(dtype)\n",
    "    m_sd = model.state_dict()\n",
    "    m1_sd = model1.state_dict()\n",
    "    m2_sd = model2.state_dict()\n",
    "    \n",
    "    for key in m_sd:\n",
    "        m_sd[key] = m1_sd[key] + m2_sd[key]\n",
    "    model.load_state_dict(m_sd)\n",
    "    return model\n",
    "\n",
    "def sub(model1, model2, device=\"cuda:7\", dtype=torch.float32):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    model.to(device).to(dtype)\n",
    "    m_sd = model.state_dict()\n",
    "    m1_sd = model1.state_dict()\n",
    "    m2_sd = model2.state_dict()\n",
    "    \n",
    "    for key in m_sd:\n",
    "        m_sd[key] = m1_sd[key] - m2_sd[key]\n",
    "    model.load_state_dict(m_sd)\n",
    "    return model\n",
    "\n",
    "def scale(model1, alpha=1.0, device=\"cuda:7\", dtype=torch.float32):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    model.to(device).to(dtype)\n",
    "    m_sd = model.state_dict()\n",
    "    m1_sd = model1.state_dict()\n",
    "    \n",
    "    for key in m_sd:\n",
    "        m_sd[key] = m1_sd[key] * alpha\n",
    "    model.load_state_dict(m_sd)\n",
    "    return model\n",
    "\n",
    "def slerp(model1, model2, t=0.5):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    m_sd = model.state_dict()\n",
    "    m1_sd = model1.state_dict()\n",
    "    m2_sd = model2.state_dict()\n",
    "    \n",
    "    for key in m_sd:\n",
    "        w1 = m1_sd[key]\n",
    "        w2 = m2_sd[key]\n",
    "        norm_w1 = w1 / torch.norm(w1.to(torch.float32))\n",
    "        norm_w2 = w2 / torch.norm(w2.to(torch.float32))\n",
    "        dot_product = torch.clamp(torch.sum(norm_w1 * norm_w2), -1.0, 1.0)\n",
    "        theta = torch.acos(dot_product)\n",
    "\n",
    "        if theta.item() == 0.0:\n",
    "            m_sd[key] = w1\n",
    "        else:\n",
    "            m_sd[key] = (\n",
    "                torch.sin((1 - t) * theta) / torch.sin(theta) * w1 +\n",
    "                torch.sin(t * theta) / torch.sin(theta) * w2\n",
    "            )\n",
    "    model.load_state_dict(m_sd)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82948d39-f17b-4b0f-a067-694f9ea10232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0  [0.924375, 0.34, 0.33625, 0.37]\n",
      "Alpha: 1e-06  [0.924375, 0.33775, 0.340375, 0.3675]\n",
      "Alpha: 1e-05  [0.924375, 0.33375, 0.335125, 0.371625]\n",
      "Alpha: 0.0001  [0.924375, 0.3425, 0.33525, 0.368]\n",
      "Alpha: 0.001  [0.923875, 0.336125, 0.332, 0.372375]\n",
      "Alpha: 0.01  [0.9255, 0.345375, 0.341375, 0.382875]\n",
      "Alpha: 0.1  [0.933875, 0.41625, 0.417375, 0.504]\n",
      "Alpha: 1  [0.1, 0.1, 0.1, 0.1]\n",
      "Alpha: 10.0  [0.1, 0.1, 0.1, 0.1]\n",
      "Alpha: 100.0  [0.1, 0.1, 0.1, 0.1]\n",
      "Alpha: 1000.0  [0.1, 0.1, 0.1, 0.1]\n"
     ]
    }
   ],
   "source": [
    "tv1 = sub(rain, base)\n",
    "tv2 = sub(fog, base)\n",
    "tv3 = sub(snow, base)\n",
    "avg = add(add(tv1, tv2), tv3)\n",
    "\n",
    "for alpha in [0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3]:\n",
    "    model = add(base, scale(avg, alpha))\n",
    "    \n",
    "    result = evaluate(\n",
    "        model,\n",
    "        batch_size = 256,\n",
    "        num_workers = 8,\n",
    "        domains = [\"base\", \"rain\", \"fog\", \"snow\"],\n",
    "        device = \"cuda:7\",\n",
    "        dtype = torch.float16\n",
    "    )\n",
    "    print(f\"Alpha: {alpha} \", [result[domain][\"accuracy\"] for domain in [\"base\", \"rain\", \"fog\", \"snow\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b6933c-0a94-41d3-af0d-944ad887326b",
   "metadata": {},
   "source": [
    "## SLERP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3c4b98b-270e-4b5f-9cb6-83c4a37a6ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 0.0\n",
      "SLERP rain->fog  [0.652875, 0.829625, 0.6965, 0.112]\n",
      "t = 0.1\n",
      "SLERP rain->fog  [0.588625, 0.53025, 0.5085, 0.1145]\n",
      "t = 0.2\n",
      "SLERP rain->fog  [0.509125, 0.36125, 0.3845, 0.10925]\n",
      "t = 0.3\n",
      "SLERP rain->fog  [0.455125, 0.273875, 0.3045, 0.110125]\n",
      "t = 0.4\n",
      "SLERP rain->fog  [0.4145, 0.23825, 0.27325, 0.11225]\n",
      "t = 0.5\n",
      "SLERP rain->fog  [0.38675, 0.209875, 0.253375, 0.110375]\n",
      "t = 0.6\n",
      "SLERP rain->fog  [0.361625, 0.1955, 0.24625, 0.110125]\n",
      "t = 0.7\n",
      "SLERP rain->fog  [0.347375, 0.1975, 0.244625, 0.10925]\n",
      "t = 0.8\n",
      "SLERP rain->fog  [0.34475, 0.236375, 0.27325, 0.10975]\n",
      "t = 0.9\n",
      "SLERP rain->fog  [0.359625, 0.420875, 0.440125, 0.109125]\n",
      "t = 1.0\n",
      "SLERP rain->fog  [0.336, 0.588125, 0.834, 0.10925]\n"
     ]
    }
   ],
   "source": [
    "for t in range(11):\n",
    "    print(f\"t = {t/10}\")\n",
    "    model1 = slerp(rain, fog, t/10)\n",
    "    model2 = slerp(fog, snow, t/10)\n",
    "    model3 = slerp(snow, rain, t/10)\n",
    "\n",
    "    result = evaluate(\n",
    "        model1,\n",
    "        batch_size = 256,\n",
    "        num_workers = 8,\n",
    "        domains = [\"base\", \"rain\", \"fog\", \"snow\"],\n",
    "        device = \"cuda:7\",\n",
    "        dtype = torch.float16\n",
    "    )\n",
    "    print(f\"SLERP rain->fog \", [result[domain][\"accuracy\"] for domain in [\"base\", \"rain\", \"fog\", \"snow\"]])\n",
    "\n",
    "    result = evaluate(\n",
    "        model2,\n",
    "        batch_size = 256,\n",
    "        num_workers = 8,\n",
    "        domains = [\"base\", \"rain\", \"fog\", \"snow\"],\n",
    "        device = \"cuda:7\",\n",
    "        dtype = torch.float16\n",
    "    )\n",
    "    print(f\"SLERP fog->snow \", [result[domain][\"accuracy\"] for domain in [\"base\", \"rain\", \"fog\", \"snow\"]])\n",
    "\n",
    "    result = evaluate(\n",
    "        model3,\n",
    "        batch_size = 256,\n",
    "        num_workers = 8,\n",
    "        domains = [\"base\", \"rain\", \"fog\", \"snow\"],\n",
    "        device = \"cuda:7\",\n",
    "        dtype = torch.float16\n",
    "    )\n",
    "    print(f\"SLERP snow->rain \", [result[domain][\"accuracy\"] for domain in [\"base\", \"rain\", \"fog\", \"snow\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc375d3b-5f61-45e5-a8cf-ca9a7c3cae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layers(model):\n",
    "    return [\n",
    "        model.conv1,\n",
    "        model.bn1,\n",
    "        model.relu,\n",
    "        model.maxpool,\n",
    "        model.layer1,\n",
    "        model.layer2,\n",
    "        model.layer3,\n",
    "        model.layer4,\n",
    "        model.avgpool,\n",
    "        model.fc\n",
    "    ]\n",
    "\n",
    "# test_dataset = STL10Dataset(test_images, test_labels, domain=domain)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82f0fe2-b89d-43fb-ad4e-8646e37bec4a",
   "metadata": {},
   "source": [
    "## TIES Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33304814-9a38-4f8b-bd29-26d465bee37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0 [0.924375, 0.339, 0.3325, 0.3725]\n",
      "Alpha: 1e-06 [0.924375, 0.338625, 0.334, 0.373]\n",
      "Alpha: 1e-05 [0.924375, 0.332125, 0.337125, 0.37125]\n",
      "Alpha: 0.0001 [0.924375, 0.338625, 0.331875, 0.369125]\n",
      "Alpha: 0.001 [0.924625, 0.341, 0.333625, 0.374]\n",
      "Alpha: 0.01 [0.9265, 0.34275, 0.345625, 0.382]\n",
      "Alpha: 0.1 [0.8855, 0.29375, 0.32475, 0.317125]\n",
      "Alpha: 1.0 [0.1, 0.1, 0.1, 0.1]\n",
      "Alpha: 100.0 [0.1, 0.1, 0.1, 0.1]\n",
      "Alpha: 100.0 [0.1, 0.1, 0.1, 0.1]\n",
      "Alpha: 1000.0 [0.1, 0.1, 0.1, 0.1]\n",
      "Alpha: 10000.0 [0.1, 0.1, 0.1, 0.1]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:7\"\n",
    "dtype = torch.float32\n",
    "\n",
    "def get_empty_state(device, dtype):\n",
    "    result = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    result.fc = torch.nn.Linear(result.fc.in_features, 10)\n",
    "    result.to(device).to(dtype)\n",
    "    result_state = result.state_dict()\n",
    "    for k, v in result_state.items():\n",
    "        result_state[k] = torch.zeros_like(v)\n",
    "    return result_state\n",
    "\n",
    "def load_model(domain):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    model.load_state_dict(torch.load(f\"./ckpts/resnet50_{domain}.pth\"))\n",
    "    return model.to(device).to(dtype)\n",
    "\n",
    "def get_mask(tensor1, tensor2):\n",
    "    mask = ((tensor1 > 0) & (tensor2 > 0)) | ((tensor1 < 0) & (tensor2 < 0)) | ((tensor1 == 0) & (tensor2 == 0))\n",
    "    return mask\n",
    "\n",
    "base = load_model(\"base\")\n",
    "rain = load_model(\"rain\")\n",
    "fog = load_model(\"fog\")\n",
    "snow = load_model(\"snow\")\n",
    "\n",
    "km = 0.2\n",
    "alpha = 0.1\n",
    "init = base\n",
    "ftms = [rain, fog, snow]\n",
    "\n",
    "# Step 1: create task vectors and trim redundant parameters\n",
    "tvs = []\n",
    "for m in ftms:\n",
    "    \n",
    "    result = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    result.fc = torch.nn.Linear(result.fc.in_features, 10)\n",
    "    result.to(device).to(dtype)\n",
    "    result_state = result.state_dict()\n",
    "    \n",
    "    tv = sub(m, init, device, dtype)\n",
    "    tv_state = tv.state_dict()\n",
    "    vals, indices = torch.sort(torch.abs(torch.concat([v.flatten() for k, v in tv_state.items()], dim=0)), descending=True)\n",
    "    k_min = vals[int(vals.shape[0] * km)]\n",
    "    for k, v in tv_state.items():\n",
    "        result_state[k][torch.abs(v) < k_min] = 0\n",
    "\n",
    "    result.load_state_dict(result_state) \n",
    "    tvs.append(result)\n",
    "\n",
    "# Step 2: Elect Final Signs\n",
    "gamma = add(add(tvs[0], tvs[1], device, dtype), tvs[2], device, dtype)\n",
    "gamma_state = gamma.state_dict()\n",
    "\n",
    "# Step 3: Disjoint Merge\n",
    "result_state = get_empty_state(device, dtype)\n",
    "Ap = get_empty_state(device, dtype)\n",
    "\n",
    "for tv in tvs:\n",
    "    tv_state = tv.state_dict()\n",
    "    for k in result_state:\n",
    "        mask = get_mask(tv_state[k], gamma_state[k])\n",
    "        result_state[k] += tv_state[k] * mask\n",
    "        Ap[k] += mask\n",
    "\n",
    "for k, v in result_state.items():\n",
    "    result_state[k] = v / Ap[k]\n",
    "\n",
    "resultm = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "resultm.fc = torch.nn.Linear(result.fc.in_features, 10)\n",
    "resultm.to(device).to(dtype)\n",
    "resultm.load_state_dict(result_state)\n",
    "\n",
    "for alpha in [0, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e2, 1e2, 1e3, 1e4]:\n",
    "\n",
    "    model = add(base, scale(resultm, alpha, device, dtype), device, dtype)\n",
    "    \n",
    "    result = evaluate(\n",
    "        model,\n",
    "        batch_size = 256,\n",
    "        num_workers = 8,\n",
    "        domains = [\"base\", \"rain\", \"fog\", \"snow\"],\n",
    "        device = \"cuda:7\",\n",
    "        dtype = torch.float16\n",
    "    )\n",
    "    print(f\"Alpha: {alpha}\", [result[domain][\"accuracy\"] for domain in [\"base\", \"rain\", \"fog\", \"snow\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbef450-312c-41a6-b347-c1a888043663",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Benchmarks\n",
    "## domain           base    rain      fog     snow\n",
    "## resnet50_base   92.175   33.47   33.48    36.96\n",
    "## resnet50_rain   46.775  82.8375  64.025    13.5\n",
    "## resnet50_fog    33.63   56.987   84.0125   10.7\n",
    "## resnet50_snow   47.89   26.92    23.612    85.03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4edbb-2012-418e-bc7c-7b9e8b12a0f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Layer Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04742a6c-a648-4e58-a3da-c4939a588dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.907375, 0.68825, 0.6665, 0.56975]\n"
     ]
    }
   ],
   "source": [
    "def load_model(domain):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    if domain == \"base\":\n",
    "        model.load_state_dict(torch.load(f\"./ckpts/resnet50_{domain}.pth\"))\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(f\"./ckpts/resnet50_{domain}_l.pth\"))\n",
    "    return model.to(device).to(dtype)\n",
    "\n",
    "def get_empty_state():\n",
    "    result = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    result.fc = torch.nn.Linear(result.fc.in_features, 10)\n",
    "    result.to(device).to(dtype)\n",
    "    result_state = result.state_dict()\n",
    "    for k, v in result_state.items():\n",
    "        result_state[k] = torch.zeros_like(v)\n",
    "    return result_state\n",
    "\n",
    "def get_empty_model():\n",
    "    result = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    result.fc = torch.nn.Linear(result.fc.in_features, 10)\n",
    "    result.to(device).to(dtype)\n",
    "    return result\n",
    "\n",
    "base = load_model(\"base\")\n",
    "rain = load_model(\"rain\")\n",
    "fog = load_model(\"fog\")\n",
    "snow = load_model(\"snow\")\n",
    "\n",
    "state = base.state_dict()\n",
    "for key in base_state:\n",
    "    if \"layer2\" in key:\n",
    "        state[key] = rain.state_dict()[key]\n",
    "    if \"layer3\" in key:\n",
    "        state[key] = fog.state_dict()[key]\n",
    "    if \"layer4\" in key:\n",
    "        state[key] = snow.state_dict()[key]\n",
    "    # if \"layer1\" in key:\n",
    "    #     state[key] = snow.state_dict()[key]\n",
    "\n",
    "model = get_empty_model()\n",
    "model.load_state_dict(state)\n",
    "result = evaluate(\n",
    "    model,\n",
    "    batch_size = 256,\n",
    "    num_workers = 8,\n",
    "    domains = [\"base\", \"rain\", \"fog\", \"snow\"],\n",
    "    device = \"cuda:7\",\n",
    "    dtype = torch.float16\n",
    ")\n",
    "print([result[domain][\"accuracy\"] for domain in [\"base\", \"rain\", \"fog\", \"snow\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f3553-3003-4064-9f96-2aa8658c428b",
   "metadata": {},
   "source": [
    "## TALL Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c1956b1f-b18a-40a1-b57c-3159893499a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alpha: 0.0 [92.4375, 34.225, 33.225, 37.3375]\n",
      "Alpha: 0.05 [95.0125, 55.800000000000004, 56.637499999999996, 55.225]\n",
      "Alpha: 0.1 [90.8125, 68.5125, 64.2375, 57.2625]\n",
      "Alpha: 0.15 [89.6625, 67.5625, 63.337500000000006, 56.8875]\n",
      "Alpha: 0.2 [88.725, 66.625, 61.625, 55.800000000000004]\n",
      "Alpha: 0.25 [94.2625, 42.125, 41.9, 45.787499999999994]\n",
      "Alpha: 0.3 [93.5875, 37.3, 37.125, 42.375]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:7\"\n",
    "dtype = torch.float32\n",
    "\n",
    "def get_empty_state():\n",
    "    result = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    result.fc = torch.nn.Linear(result.fc.in_features, 10)\n",
    "    result.to(device).to(dtype)\n",
    "    result_state = result.state_dict()\n",
    "    for k, v in result_state.items():\n",
    "        result_state[k] = torch.zeros_like(v)\n",
    "    return result_state\n",
    "\n",
    "def get_empty_model():\n",
    "    result = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    result.fc = torch.nn.Linear(result.fc.in_features, 10)\n",
    "    result.to(device).to(dtype)\n",
    "    return result\n",
    "\n",
    "def load_model(domain):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    model.load_state_dict(torch.load(f\"./ckpts/resnet50_{domain}.pth\"))\n",
    "    return model.to(device).to(dtype)\n",
    "\n",
    "def add(model1, model2):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    model.to(device).to(dtype)\n",
    "    m_sd = model.state_dict()\n",
    "    m1_sd = model1.state_dict()\n",
    "    m2_sd = model2.state_dict()\n",
    "    \n",
    "    for key in m_sd:\n",
    "        m_sd[key] = m1_sd[key] + m2_sd[key]\n",
    "    model.load_state_dict(m_sd)\n",
    "    return model\n",
    "\n",
    "def sub(model1, model2):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    model.to(device).to(dtype)\n",
    "    m_sd = model.state_dict()\n",
    "    m1_sd = model1.state_dict()\n",
    "    m2_sd = model2.state_dict()\n",
    "    for key in m_sd:\n",
    "        m_sd[key] = m1_sd[key] - m2_sd[key]\n",
    "    model.load_state_dict(m_sd)\n",
    "    return model\n",
    "\n",
    "def evaluate(model, batch_size, num_workers, domains, device, dtype):\n",
    "    \n",
    "    train_images, train_labels, test_images, test_labels = load_stl10()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device).to(dtype)\n",
    "    result = {}\n",
    "\n",
    "    for domain in domains:\n",
    "        \n",
    "        test_dataset = STL10Dataset(test_images, test_labels, domain=domain)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "        total_loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                inputs, labels = images.to(device).to(dtype), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        result[domain] = {\n",
    "            \"loss\": total_loss / total,\n",
    "            \"accuracy\": correct / total\n",
    "        }\n",
    "\n",
    "    return result\n",
    "\n",
    "base = load_model(\"base\")\n",
    "rain = load_model(\"rain\")\n",
    "fog = load_model(\"fog\")\n",
    "snow = load_model(\"snow\")\n",
    "\n",
    "## Step 1: Generate the mtl as mentioned in https://arxiv.org/pdf/2212.04089\n",
    "mtl = add(add(sub(rain, base), sub(fog, base)), sub(snow, base))\n",
    "mtl_state = mtl.state_dict()\n",
    "\n",
    "## Step 2: Generate the mask for mtl\n",
    "## m∗t = 1{|τt| ≥ |τMTL − τt|}\n",
    "## Derivation of mask in Appendix B of https://arxiv.org/pdf/2405.07813\n",
    "mask = get_empty_state()\n",
    "init = base.state_dict()\n",
    "domains = [\"base\", \"rain\", \"fog\", \"snow\"]\n",
    "for alpha in [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]:\n",
    "    accs = []\n",
    "    for domain in domains:\n",
    "        ftm = load_model(domain).state_dict()\n",
    "        for key in mask:\n",
    "            diff = torch.abs(mtl_state[key] - (ftm[key] - init[key]))\n",
    "            mask[key] = (torch.abs(ftm[key] - init[key]) >= (diff * alpha)).float()\n",
    "        \n",
    "        ## Step 3: Merge the model\n",
    "        model = get_empty_model()\n",
    "        model_state = model.state_dict()\n",
    "        for key in model_state:\n",
    "            model_state[key] = init[key] + mask[key] * mtl_state[key]\n",
    "        model.load_state_dict(model_state)\n",
    "        \n",
    "        ## Step 4: Standard evalatuion protocol\n",
    "        result = evaluate(\n",
    "            model,\n",
    "            batch_size = 256,\n",
    "            num_workers = 8,\n",
    "            domains = [\"rain\"],\n",
    "            device = device,\n",
    "            dtype = dtype\n",
    "        )\n",
    "        accs.append(result[domain][\"accuracy\"])\n",
    "    print(f\"Alpha: {alpha} \", accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc91e021-358e-457f-a3eb-4ae0ee1b3e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:7\"\n",
    "dtype = torch.float32\n",
    "\n",
    "def load_model(domain):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    model.load_state_dict(torch.load(f\"./ckpts/resnet50_{domain}.pth\"))\n",
    "    return model.to(device).to(dtype)\n",
    "\n",
    "def get_empty_state():\n",
    "    result = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    result.fc = torch.nn.Linear(result.fc.in_features, 10)\n",
    "    result.to(device).to(dtype)\n",
    "    result_state = result.state_dict()\n",
    "    for k, v in result_state.items():\n",
    "        result_state[k] = torch.zeros_like(v)\n",
    "    return result_state\n",
    "\n",
    "def get_empty_model():\n",
    "    result = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    result.fc = torch.nn.Linear(result.fc.in_features, 10)\n",
    "    result.to(device).to(dtype)\n",
    "    return result\n",
    "\n",
    "base = load_model(\"base\")\n",
    "rain = load_model(\"rain\")\n",
    "fog = load_model(\"fog\")\n",
    "snow = load_model(\"snow\")\n",
    "\n",
    "alpha = 1\n",
    "state = base.state_dict()\n",
    "for key in state:\n",
    "    if \"layer2\" in key:\n",
    "        state[key] = state[key] + (rain.state_dict()[key] - state[key]) * alpha\n",
    "    if \"layer3\" in key:\n",
    "        state[key] = state[key] + (fog.state_dict()[key] - state[key]) * alpha\n",
    "    if \"layer4\" in key:\n",
    "        state[key] = state[key] + (snow.state_dict()[key] - state[key]) * alpha\n",
    "    # if \"layer1\" in key:\n",
    "    #     state[key] = snow.state_dict()[key]\n",
    "\n",
    "model = get_empty_model()\n",
    "model.load_state_dict(state)\n",
    "\n",
    "# for alpha in [0, 0.5, 1, 1.05, 1.1, 0.2, 0.1]:\n",
    "#     state = base.state_dict()\n",
    "#     for key in state:\n",
    "#         if \"layer2\" in key:\n",
    "#             state[key] = state[key] + (rain.state_dict()[key] - state[key]) * alpha\n",
    "#         if \"layer3\" in key:\n",
    "#             state[key] = state[key] + (fog.state_dict()[key] - state[key]) * alpha\n",
    "#         if \"layer4\" in key:\n",
    "#             state[key] = state[key] + (snow.state_dict()[key] - state[key]) * alpha\n",
    "#         # if \"layer1\" in key:\n",
    "#         #     state[key] = snow.state_dict()[key]\n",
    "    \n",
    "#     model = get_empty_model()\n",
    "#     model.load_state_dict(state)\n",
    "#     result = evaluate(\n",
    "#         model,\n",
    "#         batch_size = 256,\n",
    "#         num_workers = 8,\n",
    "#         domains = [\"base\", \"rain\", \"fog\", \"snow\"],\n",
    "#         device = \"cuda:7\",\n",
    "#         dtype = torch.float16\n",
    "#     )\n",
    "#     print(f\"Alpha: {alpha / 10 }\", [result[domain][\"accuracy\"] * 100 for domain in [\"base\", \"rain\", \"fog\", \"snow\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "229bff2a-955d-45f8-90e4-afd68ede3ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base': {'loss': 0.001204498291015625, 'accuracy': 0.908125},\n",
       " 'rain': {'loss': 0.0037325439453125, 'accuracy': 0.68475},\n",
       " 'fog': {'loss': 0.00418292236328125, 'accuracy': 0.649875},\n",
       " 'snow': {'loss': 0.005035400390625, 'accuracy': 0.56475}}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_empty_model():\n",
    "#     result = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "#     result.fc = torch.nn.Linear(result.fc.in_features, 10)\n",
    "#     result.to(device).to(dtype)\n",
    "#     return result\n",
    "\n",
    "# model = get_empty_model()\n",
    "# model.load_state_dict(torch.load(\"./ckpts/resnet_50.pth\"))\n",
    "\n",
    "result = evaluate(\n",
    "    model,\n",
    "    batch_size = 256,\n",
    "    num_workers = 8,\n",
    "    domains = [\"base\", \"rain\", \"fog\", \"snow\"],\n",
    "    device = \"cuda:7\",\n",
    "    dtype = torch.float16\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ddfdd7f4-d42f-4454-891c-589cfb2ad986",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./ckpts/resnet_50.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e041a-7bf5-40e7-9d74-ca83c73b95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha: 0.0 [92.4375, 34.225, 33.225, 37.3375]\n",
    "# Alpha: 0.05 [95.0125, 55.800000000000004, 56.637499999999996, 55.225]\n",
    "# Alpha: 0.1 (Best) [90.8125, 68.5125, 64.2375, 57.2625]\n",
    "# Alpha: 0.15 [89.6625, 67.5625, 63.337500000000006, 56.8875]\n",
    "# Alpha: 0.2 [88.725, 66.625, 61.625, 55.800000000000004]\n",
    "# Alpha: 0.25 [94.2625, 42.125, 41.9, 45.787499999999994]\n",
    "# Alpha: 0.3 [93.5875, 37.3, 37.125, 42.375]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f6eff8-4555-4f05-a2fe-d3ba88bce52e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Neuron Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1564864c-cd31-428b-8961-e733b56653b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "activations_base = {}\n",
    "activations_rain = {}\n",
    "activations_fog = {}\n",
    "activations_snow = {}\n",
    "\n",
    "def get_activation(name, activations_dict):\n",
    "    def hook(model, input, output):\n",
    "        activations_dict[name] = output.detach().cpu()\n",
    "    return hook\n",
    "\n",
    "def register_hooks(model, activations_dict):\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "            layer.register_forward_hook(get_activation(name, activations_dict))\n",
    "\n",
    "def load_model(domain):\n",
    "    model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    model.load_state_dict(torch.load(f\"./ckpts/resnet50_{domain}.pth\"))\n",
    "    return model\n",
    "\n",
    "base = load_model(\"base\")\n",
    "rain = load_model(\"rain\")\n",
    "fog = load_model(\"fog\")\n",
    "snow = load_model(\"snow\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "models = {'base': base, 'rain': rain, 'fog': fog, 'snow': snow}\n",
    "for model in models.values():\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "register_hooks(base, activations_base)\n",
    "register_hooks(rain, activations_rain)\n",
    "register_hooks(fog, activations_fog)\n",
    "register_hooks(snow, activations_snow)\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 8\n",
    "train_images, train_labels, test_images, test_labels = load_stl10()\n",
    "\n",
    "def process_data(model, activations_dict, domain):\n",
    "    train_dataset = STL10Dataset(train_images, train_labels, domain=domain)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    with torch.no_grad():\n",
    "        for images, _ in tqdm(train_loader):\n",
    "            images = images.to(device)\n",
    "            model(images)\n",
    "\n",
    "process_data(base, activations_base, \"base\")\n",
    "process_data(rain, activations_rain, \"rain\")\n",
    "process_data(fog, activations_fog, \"fog\")\n",
    "process_data(snow, activations_snow, \"snow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b26b4-17ba-4189-9838-b0c7fc675b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_importance(activations_dict):\n",
    "    importance_scores = {}\n",
    "    for name, activation in activations_dict.items():\n",
    "        # Flatten the activations (batch_size, num_neurons)\n",
    "        activation_flat = activation.view(activation.size(0), -1)\n",
    "        # Compute mean absolute activation per neuron\n",
    "        mean_activation = activation_flat.abs().mean(dim=0)\n",
    "        importance_scores[name] = mean_activation.cpu()\n",
    "    return importance_scores\n",
    "\n",
    "# Compute importance scores for each model\n",
    "importance_base = compute_importance(activations_base)\n",
    "importance_rain = compute_importance(activations_rain)\n",
    "importance_fog = compute_importance(activations_fog)\n",
    "importance_snow = compute_importance(activations_snow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58956b9-8f22-4356-9090-61a2325a50b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_neurons(importance_scores):\n",
    "    ranked_neurons = {}\n",
    "    for name, scores in importance_scores.items():\n",
    "        # Get indices of neurons sorted by importance in descending order\n",
    "        sorted_indices = torch.argsort(scores, descending=True)\n",
    "        ranked_neurons[name] = sorted_indices\n",
    "    return ranked_neurons\n",
    "\n",
    "# Get ranked neurons for each model\n",
    "ranked_base = rank_neurons(importance_base)\n",
    "ranked_rain = rank_neurons(importance_rain)\n",
    "ranked_fog = rank_neurons(importance_fog)\n",
    "ranked_snow = rank_neurons(importance_snow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765d4bc-cf35-4349-a8d1-ffe3494d8e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_importance(importance_scores):\n",
    "    normalized_scores = {}\n",
    "    for name, scores in importance_scores.items():\n",
    "        norm_scores = (scores - scores.min()) / (scores.max() - scores.min())\n",
    "        normalized_scores[name] = norm_scores\n",
    "    return normalized_scores\n",
    "\n",
    "# Normalize importance scores\n",
    "importance_rain_normalized = normalize_importance(importance_rain)\n",
    "importance_fog_normalized = normalize_importance(importance_fog)\n",
    "importance_snow_normalized = normalize_importance(importance_snow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f751712-be4d-46fb-bb75-67845d719310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming importance scores are stored as dictionaries: {layer_name: tensor of importance scores}\n",
    "\n",
    "def create_importance_dataframe(layers, importance_scores_dicts):\n",
    "    data = {}\n",
    "    for domain, importance_scores in importance_scores_dicts.items():\n",
    "        for layer_name in layers:\n",
    "            scores = importance_scores[layer_name].numpy()\n",
    "            for idx, score in enumerate(scores):\n",
    "                key = f\"{layer_name}_{idx}\"\n",
    "                if key not in data:\n",
    "                    data[key] = {}\n",
    "                data[key][domain] = score\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "    return df\n",
    "\n",
    "# Collect importance scores from all domains\n",
    "importance_scores_dicts = {\n",
    "    'rain': importance_rain,\n",
    "    'fog': importance_fog,\n",
    "    'snow': importance_snow\n",
    "}\n",
    "\n",
    "# Get the list of layers\n",
    "layers = importance_rain.keys()\n",
    "\n",
    "# Create the DataFrame\n",
    "importance_df = create_importance_dataframe(layers, importance_scores_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59b31b-0533-45cf-847e-9d7fa95e1b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize importance scores per domain\n",
    "def normalize_importance_scores(df):\n",
    "    for domain in ['rain', 'fog', 'snow']:\n",
    "        max_score = df[domain].max()\n",
    "        min_score = df[domain].min()\n",
    "        df[domain] = (df[domain] - min_score) / (max_score - min_score)\n",
    "    return df\n",
    "\n",
    "# Normalize the DataFrame\n",
    "importance_df = normalize_importance_scores(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062350c8-8604-457c-8396-354f39f1f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set importance threshold (e.g., top 20% neurons are considered important)\n",
    "importance_threshold = 0.8\n",
    "\n",
    "def determine_important_neurons(df, threshold):\n",
    "    important_neurons = {}\n",
    "    for domain in ['rain', 'fog', 'snow']:\n",
    "        domain_scores = df[domain].dropna()\n",
    "        threshold_value = domain_scores.quantile(threshold)\n",
    "        important = domain_scores[domain_scores >= threshold_value].index.tolist()\n",
    "        important_neurons[domain] = important\n",
    "    return important_neurons\n",
    "\n",
    "# Get important neurons for each domain\n",
    "important_neurons = determine_important_neurons(importance_df, importance_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c113ac-6b7d-4c57-a5f0-597508488f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify shared and domain-specific neurons\n",
    "shared_neurons = set(important_neurons['rain']) & set(important_neurons['fog']) & set(important_neurons['snow'])\n",
    "domain_specific_neurons = {\n",
    "    'rain': set(important_neurons['rain']) - shared_neurons,\n",
    "    'fog': set(important_neurons['fog']) - shared_neurons,\n",
    "    'snow': set(important_neurons['snow']) - shared_neurons\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97844ed6-a3fd-4b1f-8340-005eef574821",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of shared neurons: {len(shared_neurons)}\")\n",
    "for domain in ['rain', 'fog', 'snow']:\n",
    "    print(f\"Number of domain-specific neurons in {domain}: {len(domain_specific_neurons[domain])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10803d-4853-4cef-8729-c1ebd7545ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_state_dict = {}\n",
    "\n",
    "for name, param in base.state_dict().items():\n",
    "    # Get parameter tensors from each model\n",
    "    param_rain = rain.state_dict()[name]\n",
    "    param_fog = fog.state_dict()[name]\n",
    "    param_snow = snow.state_dict()[name]\n",
    "    \n",
    "    # Check if the parameter is a weight tensor\n",
    "    if 'weight' in name and len(param.shape) >= 1:\n",
    "        # Process per neuron/filter\n",
    "        merged_param = param.clone()\n",
    "        num_neurons = param.shape[0]\n",
    "        for i in range(num_neurons):\n",
    "            # Get importance scores\n",
    "            imp_rain = importance_rain.get(name, torch.zeros(num_neurons))[i]\n",
    "            imp_fog = importance_fog.get(name, torch.zeros(num_neurons))[i]\n",
    "            imp_snow = importance_snow.get(name, torch.zeros(num_neurons))[i]\n",
    "            \n",
    "            # Normalize importance scores (if not already normalized)\n",
    "            total_imp = imp_rain + imp_fog + imp_snow + 1e-8  # Add epsilon to avoid division by zero\n",
    "            imp_rain /= total_imp\n",
    "            imp_fog /= total_imp\n",
    "            imp_snow /= total_imp\n",
    "            \n",
    "            # Merge weights based on importance\n",
    "            merged_param[i] = (imp_rain * param_rain[i] +\n",
    "                               imp_fog * param_fog[i] +\n",
    "                               imp_snow * param_snow[i])\n",
    "        merged_state_dict[name] = merged_param\n",
    "    else:\n",
    "        # For biases and other parameters, average them\n",
    "        merged_state_dict[name] = (param_rain + param_fog + param_snow) / 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3713b6d6-4b4b-45d2-bbf8-546693814c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new ResNet50 model instance\n",
    "unified_model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)\n",
    "unified_model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "# Load the merged weights\n",
    "unified_model.load_state_dict(merged_state_dict)\n",
    "\n",
    "# Set to evaluation mode\n",
    "unified_model.eval()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd148d4f-93e4-4d9d-9ca8-5918e4a03b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate(\n",
    "    unified_model,\n",
    "    batch_size = 256,\n",
    "    num_workers = 8,\n",
    "    domains = [\"base\", \"rain\", \"fog\", \"snow\"],\n",
    "    device = \"cuda:7\",\n",
    "    dtype = torch.float16\n",
    ")\n",
    "print([result[domain][\"accuracy\"] for domain in [\"base\", \"rain\", \"fog\", \"snow\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a654fb60-f199-4363-8de5-a0484752efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we have a unified importance score mask\n",
    "unified_mask = create_unified_mask(important_neurons)\n",
    "\n",
    "def masked_forward_pass(model, x, mask):\n",
    "    activations = {}\n",
    "    def hook(name):\n",
    "        def hook_fn(module, input, output):\n",
    "            if name in mask:\n",
    "                output = output * mask[name]\n",
    "            return output\n",
    "        return hook_fn\n",
    "    \n",
    "    # Register hooks\n",
    "    handles = []\n",
    "    for name, layer in model.named_modules():\n",
    "        if name in mask:\n",
    "            handle = layer.register_forward_hook(hook(name))\n",
    "            handles.append(handle)\n",
    "    \n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    \n",
    "    # Remove hooks\n",
    "    for handle in handles:\n",
    "        handle.remove()\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Use the modified forward pass during inference\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = masked_forward_pass(base_model, images, unified_mask)\n",
    "        # Compute accuracy or other metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
